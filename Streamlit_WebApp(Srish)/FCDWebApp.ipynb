{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4216,"status":"ok","timestamp":1660713278062,"user":{"displayName":"Srish Kulkarni","userId":"04028341672350324888"},"user_tz":-330},"id":"T3RZ8O-VSoDD"},"outputs":[],"source":["!pip install streamlit -q"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":870,"status":"ok","timestamp":1660713288306,"user":{"displayName":"Srish Kulkarni","userId":"04028341672350324888"},"user_tz":-330},"id":"wIsNkC9iZxgD","outputId":"1e43c75c-46e8-4bae-d2ca-be4cfaa18591"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Spyder Editor\n","\n","This is a temporary script file.\n","\"\"\"\n","\n","import streamlit as st\n","st. set_page_config(layout=\"wide\", page_icon=\":FCD:\")\n","st.set_option('deprecation.showPyplotGlobalUse', False)\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import time\n","import matplotlib.pyplot as plt\n","plt.style.use('fivethirtyeight')\n","plt.style.use('Solarize_Light2')\n","\n","from sklearn.inspection import permutation_importance\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix,accuracy_score\n","from sklearn.decomposition import PCA\n","\n","#--------------------------------------------------------------------------------------------------------------------------------------------------------\n","start_time=time.time()  #Program Start time\n","#Titles\n","tit1,tit2 = st.columns((4, 1))\n","tit1.markdown(\"\u003ch1 style='text-align: center;'\u003e\u003cu\u003eFuel Classification for  Fire Calorimetry Database\u003c/u\u003e \u003c/h1\u003e\",unsafe_allow_html=True)\n","tit2.image(\"/content/Fire.jpg\")\n","st.sidebar.title(\"Dataset and Classifier\")\n","\n","dataset_name=st.sidebar.selectbox(\"Select Dataset: \",('Normal',\"Augmented\"))\n","classifier_name = st.sidebar.selectbox(\"Select Classifier: \",(\"Logistic Regression\",\"Decision Trees\",\"Bagging\",\n","                                                              \"Random Forest\",\"AdaBoost Classifier\"))\n","\n","LE=LabelEncoder()\n","def get_dataset(dataset_name):\n","    if dataset_name==\"Normal\":\n","        data=pd.read_csv(\"/content/FCDorg.csv\")\n","        st.header(\"Classification on Normal Data\")\n","        return data\n","\n","    else:\n","        data=pd.read_csv(\"/content/FCDaug.csv\")\n","        st.header(\"Classification on Augmented Data\")\n","        return data\n","\n","data = get_dataset(dataset_name)\n","\n","def selected_dataset(dataset_name):\n","    if dataset_name == \"Normal\":\n","        X=data.drop([\"fuel_type\"],axis=1)\n","        Y=data.fuel_type\n","        return X,Y\n","\n","    elif dataset_name == \"Augmented\":\n","        X = data.drop([\"fuel_type\"], axis=1)\n","        Y = data.fuel_type\n","        return X,Y\n","lables = [\"Cellulose\", \"Methane\", \"Natural Gas\",\"Other Fuels\", \"Plastic\", \"Propane\", \"Wood (MDF)\"]\n","X,Y=selected_dataset(dataset_name)\n","\n","#Plot output variable\n","def plot_op(dataset_name):\n","    col1, col2 = st.columns((1, 5))\n","    plt.figure(figsize=(12, 3))\n","    plt.title(\"Classes in 'Y'\")\n","    if dataset_name == \"Normal\":\n","        col1.write(Y)\n","        sns.countplot(Y)\n","        col2.pyplot()\n","\n","    elif dataset_name == \"Augmented\":\n","        col1.write(Y)\n","        sns.countplot(Y)\n","        col2.pyplot()\n","\n","st.write(data)\n","st.write(\"Shape of dataset: \",data.shape)\n","st.write(\"Number of classes: \",Y.nunique())\n","plot_op(dataset_name)\n","\n","\n","def add_parameter_ui(clf_name):\n","    params={}\n","    st.sidebar.write(\"Select values: \")\n","\n","    if clf_name == \"Logistic Regression\":\n","        R = st.sidebar.slider(\"Regularization\",0.1,10.0,step=0.1)\n","        MI = st.sidebar.slider(\"max_iter\",50,400,step=50)\n","        params[\"R\"] = R\n","        params[\"MI\"] = MI\n","\n","\n","    elif clf_name == \"Decision Trees\":\n","        M = st.sidebar.slider(\"max_depth\", 2, 20)\n","        C = st.sidebar.selectbox(\"Criterion\", (\"gini\", \"entropy\"))\n","        SS = st.sidebar.slider(\"min_samples_split\",2,10)\n","        params[\"M\"] = M\n","        params[\"C\"] = C\n","        params[\"SS\"] = SS\n","\n","    elif clf_name == \"Bagging\":\n","        N = st.sidebar.slider(\"n_estimators\",1,50,step=1,value=10)\n","        params[\"N\"] = N\n","        \n","    elif clf_name == \"Random Forest\":\n","        N = st.sidebar.slider(\"n_estimators\",10,300,step=20,value=100)\n","        M = st.sidebar.slider(\"max_depth\",2,20)\n","        C = st.sidebar.selectbox(\"Criterion\",(\"gini\",\"entropy\"))\n","        F = st.sidebar.selectbox(\"max_features\",(\"auto\",\"sqrt\", \"log2\"))\n","        params[\"N\"] = N\n","        params[\"M\"] = M\n","        params[\"C\"] = C\n","        params[\"F\"] = F\n","\n","    elif clf_name == \"AdaBoost Classifier\":\n","        N = st.sidebar.slider(\"n_estimators\", 10, 300, step=40, value=10)\n","        LR = st.sidebar.slider(\"Learning Rate\", 0.01, 10.0,1.0)\n","        params[\"N\"] = N\n","        params[\"LR\"] = LR\n","\n","\n","    RS=st.sidebar.slider(\"Random State\",0,100)\n","    params[\"RS\"] = RS\n","    return params\n","\n","params = add_parameter_ui(classifier_name)\n","\n","def get_classifier(clf_name,params):\n","    global clf\n","    if clf_name == \"Logistic Regression\":\n","        clf = LogisticRegression(C=params[\"R\"],max_iter=params[\"MI\"])\n","\n","    elif clf_name == \"Decision Trees\":\n","        clf = DecisionTreeClassifier(max_depth=params[\"M\"],criterion=params[\"C\"],min_samples_split= params[\"SS\"])\n","        \n","    elif clf_name == \"Bagging\":\n","        clf = BaggingClassifier(n_estimators = params[\"N\"])\n","\n","    elif clf_name == \"Random Forest\":\n","        clf = RandomForestClassifier(n_estimators=params[\"N\"],max_depth=params[\"M\"],criterion=params[\"C\"], max_features=params[\"F\"])\n","\n","    elif clf_name == \"AdaBoost Classifier\":\n","        clf = AdaBoostClassifier(n_estimators=params[\"N\"],learning_rate=params[\"LR\"])        \n","\n","    return clf\n","\n","clf = get_classifier(classifier_name,params)\n","\n","#Build Model\n","def model():\n","    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n","    \n","    if classifier_name == \"Logistic Regression\":\n","        #MinMax Scaling / Normalization of data\n","        Std_scaler = StandardScaler()\n","        X_train = Std_scaler.fit_transform(X_train)\n","        X_test = Std_scaler.transform(X_test)\n","    \n","        clf.fit(X_train,Y_train)\n","        Y_pred_train = clf.predict(X_train)\n","        Y_pred_test = clf.predict(X_test) \n","        return X_train, X_test, Y_train, Y_pred_train, Y_pred_test ,Y_test\n","    else:\n","        clf.fit(X_train, Y_train)\n","        Y_pred_train = clf.predict(X_train)\n","        Y_pred_test = clf.predict(X_test)\n","        return X_train, X_test, Y_train, Y_pred_train, Y_pred_test ,Y_test\n","\n","X_train, X_test, Y_train, Y_pred_train, Y_pred_test ,Y_test = model()\n","\n","def conmatrix(X, y, model):\n","    return confusion_matrix(y, model.predict(X))\n","\n","#Plot Output\n","def compute():\n","    #Plot PCA\n","    clf_result = permutation_importance(clf,X_train,Y_train, random_state = 0)\n","    cols = X.columns\n","    mean = clf_result.importances_mean\n","    std = clf_result.importances_std\n","    df_res = pd.DataFrame({'features':cols, 'importance':mean, 'importance_std': std}).sort_values('importance', ascending=False, ignore_index=True)\n","    plt.figure(figsize=(10,10))\n","    sns.barplot(x='importance',y='features', data = df_res, orient='h', xerr = df_res[\"importance_std\"] )\n","    plt.title(\"Permutation Importance\\n\", fontsize=20);\n","    st.pyplot()\n","\n","    #c1, c2 = st.columns((4,3))\n","    #Output plot\n","    plt.figure(figsize=(12,6))\n","    st.write(\"Permutation importance dataframe\",df_res)\n","    var1 = df_res['features'][0]\n","    var2 = df_res['features'][1]\n","    st.write(\"Top 1 : \",var1)\n","    st.write(\"Top 2: \", var2)\n","    sns.scatterplot(x =data[var1] , y = data[var2] , hue = data['fuel_type'])\n","    plt.title(\"Distribution of Classes according to top 2 variables\")\n","    st.pyplot()\n","\n","    #Confusion Matrix\n","    c1, c2 = st.columns((4,4))\n","    cm = conmatrix(X_train, Y_train, clf)\n","    l = [\"Cellulose\", \"Methane\", \"Natural Gas\",\"Other Fuels\", \"Plastic\", \"Propane\", \"Wood (MDF)\"]\n","    plt.figure(figsize=(12, 7.5))\n","    sns.heatmap(cm,annot=True,cmap='Blues',linewidths=2,fmt='g',xticklabels=l, yticklabels=l);\n","    plt.title(\"Confusion Matrix for Train\",fontsize=15)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    c1.pyplot()\n","    \n","    \n","    cm = conmatrix(X_test, Y_test, clf)\n","    plt.figure(figsize=(12, 7.5))\n","    sns.heatmap(cm,annot=True,cmap='Blues',linewidths=2,fmt='g',xticklabels=l, yticklabels=l);\n","    plt.title(\"Confusion Matrix for test\",fontsize=15)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"True\")\n","    c2.pyplot()\n","\n","    #Calculate Metrics\n","    acc = accuracy_score(Y_train,Y_pred_train)\n","    mse=mean_squared_error(Y_train,Y_pred_train)\n","    precision =  precision_score(Y_train, Y_pred_train, average='macro')\n","    recall = recall_score(Y_train, Y_pred_train,average='macro')\n","    fscore = f1_score(Y_train, Y_pred_train, average='macro')\n","    st.subheader(\"Training Metrics of the model: \")\n","    st.text('Precision: {} \\nRecall: {} \\nF1-Score: {} \\nAccuracy: {} %\\nMean Squared Error: {}'.format(\n","        round(precision, 3), round(recall, 3), round(fscore,3), round((acc*100),3), round((mse),3)))\n","    \n","    \n","    acct = accuracy_score(Y_test,Y_pred_test)\n","    mset=mean_squared_error(Y_test,Y_pred_test)\n","    precisiont =  precision_score(Y_test, Y_pred_test, average='macro')\n","    recallt = recall_score(Y_test, Y_pred_test,average='macro')\n","    fscoret = f1_score(Y_test, Y_pred_test, average='macro')\n","    st.subheader(\"Testing Training Metrics of the model: \")\n","    st.text('Precision: {} \\nRecall: {} \\nF1-Score: {} \\nAccuracy: {} %\\nMean Squared Error: {}'.format(\n","        round(precisiont, 3), round(recallt, 3), round(fscoret,3), round((acct*100),3), round((mset),3)))\n","\n","st.markdown(\"\u003chr\u003e\",unsafe_allow_html=True)\n","st.header(f\"1) Model for Prediction of {dataset_name}\")\n","st.subheader(f\"Classifier Used: {classifier_name}\")\n","compute()\n","\n","#Execution Time\n","end_time=time.time()\n","st.info(f\"Total execution time: {round((end_time - start_time),4)} seconds\")\n","\n","\n","#Get user values\n","def user_inputs_ui(dataset_name,data):\n","    user_val = {}\n","    if dataset_name == \"Normal\":\n","        X = data.drop([\"fuel_type\"], axis=1)\n","        for col in X.columns:\n","            name = col\n","            col = st.number_input(col, min_value=(X[col].min()*1.00000), max_value=(X[col].max()*1.00000),format=\"%.5f\")\n","            user_val[name] = round((col),4)\n","\n","    elif dataset_name == \"Augmented\":\n","        X = data.drop([\"fuel_type\"], axis=1)\n","        for col in X.columns:\n","            name = col\n","            col = st.number_input(col, min_value=(X[col].min()*1.00000), max_value=(X[col].max()*1.00000),format=\"%.5f\")\n","            user_val[name] = col\n","\n","    return user_val\n","\n","#User values\n","st.markdown(\"\u003chr\u003e\",unsafe_allow_html=True)\n","st.header(\"2) User Values\")\n","with st.expander(\"See more\"):\n","    st.markdown(\"\"\"\n","    In this section you can use your own values to predict the target variable. \n","    Input the required values below and you will get your status based on the values. \u003cbr\u003e\n","    \u003cp style='color: red;'\u003e 0 - Cellulose \u003c/p\u003e\n","    \u003cp style='color: blue;'\u003e 1 - Methane \u003c/p\u003e \n","    \u003cp style='color: #FFD700;'\u003e 2 - Natural Gas \u003c/p\u003e\n","    \u003cp style='color: green;'\u003e 3 - Other Fuels \u003c/p\u003e\n","    \u003cp style='color: #FF00FF;'\u003e 4 - Plastic\u003c/p\u003e \n","    \u003cp style='color: #33F9FF;'\u003e 5 - Propane \u003c/p\u003e\n","    \u003cp style='color: #FF3383;'\u003e 6 - Wood (MDF) \u003c/p\u003e\n","    \"\"\",unsafe_allow_html=True)\n","\n","user_val = user_inputs_ui(dataset_name,data)\n","\n","#@st.cache(suppress_st_warning=True)\n","def user_predict():\n","    global U_pred\n","    if dataset_name == \"Normal\":\n","        X = data.drop([\"fuel_type\"], axis=1)\n","        U_pred = clf.predict([[user_val[col] for col in X.columns]])\n","\n","    elif dataset_name == \"Augmented\":\n","        X = data.drop([\"fuel_type\"], axis=1)\n","        U_pred = clf.predict([[user_val[col] for col in X.columns]])\n","\n","    st.subheader(\"Your Status: \")\n","    if U_pred == 0:\n","        st.write(U_pred[0], \" - The burnt material is Cellulose :)\")\n","    if U_pred == 1:\n","        st.write(U_pred[0], \" - The burnt material is Methane :)\")\n","    if U_pred == 2:\n","        st.write(U_pred[0], \" - The burnt material is Natural Gas :)\")\n","    if U_pred == 3:\n","        st.write(U_pred[0], \" - The burnt material is Other Fuels :)\")\n","    if U_pred == 4:\n","        st.write(U_pred[0], \" - The burnt material is Plastic :)\")\n","    if U_pred == 5:\n","        st.write(U_pred[0], \" - The burnt material is Propane :)\")\n","    if U_pred == 6:\n","        st.write(U_pred[0], \" - The burnt material is Wood (MDF) :)\")\n","        \n","        \n","user_predict()  #Predict the status of user.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"c7oVZsENTfyD"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-08-17 05:14:43.889 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n","\u001b[K\u001b[?25hnpx: installed 22 in 3.819s\n","your url is: https://weak-trams-worry-104-199-139-78.loca.lt\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.199.139.78:8501\u001b[0m\n","\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  \"X does not have valid feature names, but\"\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]}],"source":["!streamlit run app.py \u0026 npx localtunnel --port 8501"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yhijqw-ls6Kf"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"FCDWebApp.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}